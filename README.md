# SpotTheBot
Курсовая работа на ПМИ ВШЭ за второй курс

На сегодняшний день люди все чаще принимают решение о приобретении того или иного товара или услуги опираясь на отзывы, оставленные покупателями в интернете. Многие мошенники используют компьютерные программы для генерации большого количества различных отзывов, что вводит пользователей в заблуждение касательно той или иной продукции. В связи с этим, выявление текстов сгенерированных ботами является очень важной и практичной задачей обработки естественного языка. 

На данный момент для детекции ботов в задаче обработки естественного языка зачастую
преобладают алгоритмы основанные на нейронных сетях. Помимо того, что нейронные сети обучаются на огромных объемах данных и требуют больших вычислительных ресурсов,
главной проблемой подобного подхода является обучение под какие-то конкретные генераторы текстов. Основной мотивацией этой работы служит построение универсального метода,
который не опирается на внутреннюю струтуру какого-либо генератора и показывает удовлетворительные результаты в самых разных случаях.

Определяющим фактором в данной работе является предположение о том, что семантические траектории (состоящие из индивидуальных эмбеддингов или $n$-грам) написанных
людьми текстов представляют из себя сложную динамическую систему, имеющую некую
структуру (в отличии от стохастических процессов). Главной целью служит введения понятия “сложности” системы и исследовать ее значения для человеческих и сгенерированных ботами текстов. В дальнейшем будет введено понятия плоскости “энтропия-сложность”, верхней и нижней границы сложности для заданной энтропии, и мы увидим, что человеческие
тексты в этой плоскости распологаются ближе к верхней границе, в то время как текста ботов
находятся ближе к нижней границе допустимой сложности. Данное наблюдение и является
ключевой идеей в этом проекте.

В итоге данная курсовая работа предлагает следующий алгоритм детекции сгенерированных текстов:
- Преобразование слов целевого языка в вектора из $R^n$ (построение семантического пространства)
- Рассмотрение данного текста в качестве многомерного временного ряда, который описывает динамику и внутреннюю структуру текста в семантическом пространстве
- Отображение временного ряда на плоскость энтропия-сложность
- Проверка того является ли ряд хаотичным или стохастическим
